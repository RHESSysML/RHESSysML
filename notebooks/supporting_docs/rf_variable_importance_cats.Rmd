---
title: "Variable Importance Template"
author: "RHESSysML Capstone Group"
date: "2/5/2022"
output: 
  rmarkdown::html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: cerulean
---

# Introduction

[RHESSys](https://github.com/RHESSys/RHESSys/wiki) output provides multiple variables that describe the response of  ecosystem biogeochemical cycling and hydrology to climate (and land use) drivers. This R Markdown document describes a workflow to apply machine learning techniques (Random Forest and Gradient Boosting) to RHESSys model output. The specific goal is to determine the most important relationships between RHESSys predictor variables and a chosen response variable in a programmatic, efficient, and reproducible manner. Permutation Importance will be our primary metric for what determines the importance of variables within each machine learning model, but additional metrics will be discussed to help you choose whether Random Forest or Gradient Boosting is a more appropriate class of model to use.

If you don’t know what Permutation Importance is right now, don’t worry! This workflow is written with ecologists in mind, not machine learning engineers or computer scientists. The details of Random Forest, Gradient Boosting, and Permutation Importance will be explained throughout the course of the document.

Specific code examples in this document will be based on RHESSys model output from the Sagehen Creek Experimental Watershed in the Sierra Nevada, CA. The data set incorporates model parameter uncertainty and topographic variability under two separate climate warming scenarios: (1) Historic temperature levels, and (2) Two degrees Celsius warming. The dataset and associated metadata can be accessed [here](https://www.hydroshare.org/resource/2a31bd57b7e74c758b7857679ffbb4c5/). 

The code below is written with Net Primary Productivity (NPP) as the response variable of interest: this means that the output of this example will offer an answer to the question: What are the most important hydroecological factors that affect NPP in an ecosystem like Sagehen Creek, _and how might that relative importance change in a warming climate?_

**Specifically, this notebook will be used to provide an example of running the workflow using only categorical predictors from RHESSys data.**

# Setup

## renv:

To help ensure reproducibility, the packages and package versions used to build this workflow have been saved via [`renv`](https://rstudio.github.io/renv/articles/renv.html). To download any missing packages and load the correct versions, run the command `renv::restore()` in the console. Doing so will not impact your package versions outside of this R Project. It may take several minutes depending on the number of discrepancies.

```{r setup, include = TRUE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen = 999)

# Standard packages
library(tidyverse)
library(here)
library(patchwork)
library(psych)
library(kableExtra)
library(zeallot)
library(DT)

# Machine Learning packages
library(caret)
library(spatialRF)
library(randomForest)
library(party)
library(partykit)
library(permimp)
library(rfUtilities)
library(randomForestExplainer)
library(fastshap)
```

```{r}
load(here::here("data", "sagehen_cats.RData"))
```


# Data Description

Next, we want to get a summary description of the data set. This is crucial for many reasons:

1.  Shows early on in the process if any variables do not have the expected range, magnitude, class, etc.

2.  Provides information on data set characteristics that are important for decisions later on in the machine learning process.

Here, we display summary statistics for the base climate scenario data.

```{r describe_data}
source(here::here("R", "summarize_data.R"))

summarize_data(df_cats)
```


# Remove Multicollinearity

Highly correlated predictor variables are not as much a concern in machine learning when creating a predictive model. However, for this process of assessing relative predictor variable importance, multicollinear variables have biased importance (Strobl et al. 2008). Therefore, these need to be handled prior to assessing feature importance.

**Categorical variables cannot be assessed using Variance Inflation Factor and Pearson Correlation**. 

# Feature Importance

Breiman's Random Forest implementation, which can be used in R using the `randomForest` package, does not require the use of one-hot encoding. This is a common technique to use categorical variables in machine learning algorithms, but has limitations for decision tree based models that benefit from reduced dimensionality.

### Hyper-Parameter Tuning

An essential part of building a machine learning model is tuning hyper-parameters. This entails altering parameters which the user has control over in order to attain an optimal model accuracy. The following tuning process has been automated and only involves `mtry`---the primary parameter that requires adjustment in a Random Forest.

The `mtry` parameter determines the number of variables randomly sampled as candidates at each split. The default value for regression is p/3, where p is the number of predictor variables.

The function below creates a vector of accuracy results of random forests using different values for `mtry`.

```{r tuning_function}
df_cats <- as.data.frame(df_cats)
```

Next, we run the function for both climate scenario data sets and visualize the results. Model error here is assessed using out-of-bag (OOB) observations in the data, which refers to observations that were not sampled during bootstrapping for the particular Random Forest being assessed. In other words OOB data were not used to train the model and can be used to test accuracy without the risk of bias incurred from model over-fitting. The best `mtry value` in the plots below will be represented by the lowest `OOB Error`.

```{r tune_rf_wy, warning = FALSE}
source(here::here("R", "tune_rf_model.R"))

set.seed(4326)

mtry <- tune_rf_model(df_cats)
bestmtry <- match(min(mtry), mtry)
ggplot(data = as.data.frame(mtry), aes(x = 1:length(mtry), y = mtry)) +
  geom_vline(xintercept = bestmtry, linetype = "dashed") +
  geom_point() +
  geom_line() +
  theme_light() +
  labs(x = "mtry value",
       y = "OOB Error",
       title = paste0("The best mtry value for ", deparse(substitute(df_cats)), " is ", bestmtry))
```

The best `mtry` value for each data set is used for the respective random forest model below.

### Random Forest Models

```{r get_random_forests}
rf <- train(x = df_cats %>% select(!response),
            y = df_cats$response,
            method = 'rf',
            .mtry = bestmtry,
            ntree = 500,
            importance = TRUE,
            replace = TRUE,
            trControl = trainControl(method = "none", seed = 4326)) # to use 10-fold cross validation, method = "cv", number = 10
```

Assessing feature importance is a complex task with many possible approaches. Tree based models like random forest offer convenient "split-improvement" measures, like mean increase in purity and minimum depth, which are intrinsically derived during model construction. However, these have been shown to be biased towards variables with many categories or large value ranges (Strobl et al. 2007). Despite some of their shortcomings, these importance measures can provide insights are further explored at the end of this document.

As the primary measure of importance we instead use partial permutation importance via the `varImp` function. Permutation importance has been tested and determined to be the most unbiased importance metric for data with a mix of categorical and continuous variables with a variety of classes and ranges, respectively. This is calculated in the following steps...

1. Assess prediction accuracy (mean squared error) of the model on the out-of-bag data.

2. Permute the values of a given variable.

3. Feed the dataset with the permuted values into the Random Forest and reassess model accuracy.

4. Importance of the permuted variable is deemed to be the mean loss in accuracy when its values were permuted.

```{r variable_importance}
imp <- varImp(rf$finalModel, scale = FALSE) %>% 
  rownames_to_column("Variable") %>% 
  mutate(Rank = rank(-Overall))
```

# Model Evaluation

The following section provides visualizations and statistics to evaluate the random forest performance.

First, simply calling the random forest shows a summary of the results, including percent variance explained.

```{r}
rf_fit <- round(tail(rf$finalModel$rsq, 1)*100, 2)

rf$finalModel
```

The model for the base climate scenario explained `r rf_wy_fit`% of variance in NPP.

# Visualize Results

Now, we can visualize the results of the Random Forest feature selection.

The variable importance plot reveals relative magnitude of importance between variables. 

```{r plot_imp}
source(here::here("R", "plot_imp.R"))

plot_imp <- plot_imp(imp)
plot_imp
```

## Previewing relationships between important predictors and NPP

The variable importance values derived from our Random Forest model allow us to investigate interesting relationships and interactions between the response term and important predictors.

```{r}
ggplot(df_cats, aes(y=response, fill = stratumID)) +
  geom_boxplot()

ggplot(df_cats, aes(y=response, fill = clim)) +
  geom_boxplot()

ggplot(df_cats, aes(y=response, fill = scen)) +
  geom_boxplot()
```

```{r}
ggplot(df_cats, aes(x=response)) +
  geom_histogram() +
  facet_wrap(~clim)

ggplot(df_cats, aes(x=response)) +
  geom_histogram() +
  facet_wrap(~stratumID)

ggplot(df_cats, aes(x=response)) +
  geom_histogram() +
  facet_wrap(~scen)
```

# Second Model - One Hot Encoding

Other implementations of random forest, including in Python's [scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), require a process known as "one-hot encoding". For each categorical variable, this involves converting each possible value into a new categorical column and assigning a binary value of 1 or 0 to those columns. 

```{r}
library(data.table)
library(mltools)

df_cats_ohe <- one_hot(as.data.table(df_cats))

df_cats_ohe <- data.frame(df_cats_ohe)
```

```{r}
set.seed(4326)

mtry <- tune_rf_model(df_cats_ohe)
bestmtry <- match(min(mtry), mtry)
ggplot(data = as.data.frame(mtry), aes(x = 1:length(mtry), y = mtry)) +
  geom_vline(xintercept = bestmtry, linetype = "dashed") +
  geom_point() +
  geom_line() +
  theme_light() +
  labs(x = "mtry value",
       y = "OOB Error",
       title = paste0("The best mtry value for ", deparse(substitute(df_cats_ohe)), " is ", bestmtry))
```

```{r}
rf <- train(x = df_cats_ohe %>% select(!response),
            y = df_cats_ohe$response,
            method = 'rf',
            .mtry = bestmtry,
            ntree = 500,
            importance = TRUE,
            replace = TRUE,
            trControl = trainControl(method = "none", seed = 4326))
```

```{r variable_importance}
imp <- varImp(rf$finalModel, scale = FALSE) %>% 
  rownames_to_column("Variable") %>% 
  mutate(Rank = rank(-Overall))
```

```{r}
rf_fit <- round(tail(rf$finalModel$rsq, 1)*100, 2)

rf$finalModel
```

```{r plot_imp}
source(here::here("R", "plot_imp.R"))

plot_imp <- plot_imp(imp)
plot_imp
```


