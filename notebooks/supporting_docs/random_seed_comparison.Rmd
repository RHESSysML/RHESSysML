---
title: "Random Seed Comparison"
author: "RHESSysML Capstone Group"
date: "2/5/2022"
output: 
  rmarkdown::html_document:
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen=999)

# Standard packages
library(tidyverse)
library(here)

# Machine Learning packages
library(caret)
library(spatialRF)
library(randomForest)
```

## Purpose

Here we test the significance of random seed on the results of the random forest variable importance measures. Since each tree in a random forest randomly samples from the data with replacement (bagging), running the model without setting a seed will always result in slightly different results. 

## Loading outputs from workflow

We will use the `df_clim0` dataset for the purpose of this example.

```{r load_data, message=FALSE}
load(here::here("data", "input", "prepared_data.RData"))

df_clim0 <- df_clim0 %>% rename(response = 1)
```

## Remove Multicollinearity

In order to replicate the workflow's results, we will remove multicollinearity.

```{r remove_multicollinearity}
# Save data frames of predictor variables for first climate scenario
df_clim0_num_preds <- df_clim0 %>% 
  select(!response & where(is.numeric))

df_clim0_fpreds <- df_clim0 %>% 
  select(!response & where(is.factor)) %>% 
  colnames()

# Find preliminary importance using random forest
imp0 <- train(x = df_clim0 %>% select(!response),
              y = df_clim0$response,
              method = 'rf',
              importance = TRUE,
              replace = TRUE,
              trControl = trainControl(method = "none", seed = 4326))

# Set preference order based on variable importance
pref_order0 <- varImp(imp0$finalModel, scale = FALSE) %>% 
  arrange(-Overall) %>% 
  rownames()

# Set thresholds
vif.threshold = 5
cor.threshold = 0.75

# Remove multicollinear variables using these functions
source(here::here("R", "remove_vif.R"))
source(here::here("R", "remove_cor.R"))

# Create list of selected variables
clim0_vif <- remove_vif(df_clim0_num_preds, vif.threshold = vif.threshold, pref_order0)$selected.variables
clim0_cor <- remove_cor(df_clim0_num_preds, cor.threshold = cor.threshold, pref_order0)$selected.variables
clim0_select_variables <- unique(append(clim0_vif, clim0_cor))

# Remove numeric variables with multicollinearity
df_clim0_reduced <- df_clim0 %>% 
  select(c(response, all_of(df_clim0_fpreds), all_of(clim0_select_variables)))
```

## Hyper-Parameter Tuning

In order to replicate the workflow's results, we will tune `mtry`.

```{r tune_mtry}
source(here::here("R", "tune_rf_model.R"))

set.seed(4326)

df_clim0_reduced <- as.data.frame(df_clim0_reduced)

mtry0 <- tune_rf_model(df_clim0_reduced)
bestmtry0 <- match(min(mtry0), mtry0)
ggplot(data = as.data.frame(mtry0), aes(x = 1:length(mtry0), y = mtry0)) +
  geom_vline(xintercept = bestmtry0, linetype = "dashed") +
  geom_point() +
  geom_line() +
  theme_light() +
  labs(x = "mtry value",
       y = "OOB Error",
       title = paste0("The best mtry value for ", deparse(substitute(df_clim0_reduced)), " is ", bestmtry0))
```

## Random Forest Models

Now, we generate 5 random forest models using the same parameters as used in the workflow. The only difference between the models are the seed.

```{r run_models}
rf1 <- train(x = df_clim0_reduced %>% select(!response), y = df_clim0_reduced$response,
             method = 'rf', .mtry = bestmtry0, ntree = 500, importance = TRUE,
             replace = TRUE, trControl = trainControl(method = "none", seed = 4326))

rf2 <- train(x = df_clim0_reduced %>% select(!response), y = df_clim0_reduced$response,
             method = 'rf', .mtry = bestmtry0, ntree = 500, importance = TRUE,
             replace = TRUE, trControl = trainControl(method = "none", seed = 1098))

rf3 <- train(x = df_clim0_reduced %>% select(!response), y = df_clim0_reduced$response,
             method = 'rf', .mtry = bestmtry0, ntree = 500, importance = TRUE,
             replace = TRUE, trControl = trainControl(method = "none", seed = 420))

rf4 <- train(x = df_clim0_reduced %>% select(!response), y = df_clim0_reduced$response,
             method = 'rf', .mtry = bestmtry0, ntree = 500, importance = TRUE,
             replace = TRUE, trControl = trainControl(method = "none", seed = 1001))

rf5 <- train(x = df_clim0_reduced %>% select(!response), y = df_clim0_reduced$response,
             method = 'rf', .mtry = bestmtry0, ntree = 500, importance = TRUE,
             replace = TRUE, trControl = trainControl(method = "none", seed = 2))
```

## Variable Importance

Now, we get variable importance using the same process as the workflow. 

```{r get_importance}
df_imp1 <- varImp(rf1$finalModel, scale = FALSE) %>% 
  rownames_to_column("Variable") %>% mutate(Rank = rank(-Overall))

df_imp2 <- varImp(rf2$finalModel, scale = FALSE) %>% 
  rownames_to_column("Variable") %>% mutate(Rank = rank(-Overall))

df_imp3 <- varImp(rf3$finalModel, scale = FALSE) %>% 
  rownames_to_column("Variable") %>% mutate(Rank = rank(-Overall))

df_imp4 <- varImp(rf4$finalModel, scale = FALSE) %>% 
  rownames_to_column("Variable") %>% mutate(Rank = rank(-Overall))

df_imp5 <- varImp(rf5$finalModel, scale = FALSE) %>% 
  rownames_to_column("Variable") %>% mutate(Rank = rank(-Overall))
```

Plotting variable importance below reveals that results can change slightly for different random seeds. However, the results are largely the same regardless of seed.

```{r plot_importance}
source(here::here("R", "plot_imp.R"))

plot_imp(df_imp1)
plot_imp(df_imp2)
plot_imp(df_imp3)
plot_imp(df_imp4)
plot_imp(df_imp5)
```