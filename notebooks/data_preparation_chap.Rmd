---
title: "Data Preparation"
author: "Alex Clippinger, Wylie Hampson, Shale Hunter, Peter Menzies"
date: '2022-06-03'
output: 
  rmarkdown::html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(RHESSysIOinR)
```

# Data Preparation

## Load Data

```{r load_data, message = FALSE}
df_raw <- readRDS(here::here("data", "input", "chap.RDS")) 
```

## Clean and Aggregate Data

First, RHESSys output will need to be aggregated and cleaned based on specific research question. Possible changes include:

1.  Changing the temporal resolution (i.e. Daily to Yearly measurements).

2.  Converting variable units (i.e. Radians to Degrees).

3.  Converting variable class (i.e. numeric/character to factor).

4.  Creating derived variables (i.e. Peak SWE).

This workflow assumes that the data are aggregated by water year. The code chunk below identifies the variables in our data set that will be converted to factors, variables that will be used to aggregate by water year, and the desired response variable. Change the inputs below to apply to your dataset in whatever way necessary (you might want to include variables that  differentiate the conditions used for a single RHESSys simulation -  examples might be treatment type, location, climate model scenario). 

The `group_cols` object selects the columns that the user wants the raw dataset to be aggregated by. 

The `factor_vars` object are the predictor variables that will be converted to factors, which allows the random forest workflow to function. Any predictor variables that should be factors instead of numeric or character should be converted. (Example: stratumID is numeric, but because there are 6 different strata, it makes more sense for them to be factors.)

The `response_var` object is the response variable that the user wants to predict. There should only be one response variable.

```{r}
# Adding water year
df_raw <- add_dates(df_raw) %>% 
  select(-yd)
```


```{r user_inputs}
group_cols <- c("wy", "basinID")
factor_vars <- c("basinID")
response_var <- "plantc"
```

```{r input_tests}
# Check class types
if (class(group_cols) != "character") {
  stop("The group columns specified above should be written as characters.")
}
if (class(factor_vars) != "character") {
  stop("The factor columns specified above should be written as characters.")
}
if (class(response_var) != "character") {
  stop("The response variable column specified above should be written as a character.")
}

# Check for factors with many categories
for (column in factor_vars) {
  num_categories = n_distinct(df_raw[,column])
  if (num_categories > 50) {
    warning(paste(column, "has", num_categories, "categories, should this column be numeric?"))
  }
  rm(num_categories, column)
}
```

Since temporal aggregation of the data set is critical to the results, we first create a function that allows us to dynamically select whether monthly or seasonal average temperatures are included as predictor variables. Setting `resolution = 'season'` does seasonal average temperatures, and `resolution = 'month'` does monthly average temperatures. By default, this function is set up to do seasonal average temperatures, and the seasons are:

Winter = Dec, Jan, Feb, March
Spring = April, May
Summer = June, July, Aug, Sep
Fall = Oct, Nov

It is possible to reassign different months to different seasons within the function as well. 

```{r aggregate_temp_function}
aggregate_temp <- function(df, 
                           resolution = 'season', 
                           winter = c(12, 1, 2, 3),
                           spring = c(4, 5),
                           summer = c(6, 7, 8, 9),
                           fall = c(10, 11)) {
  
  if (resolution == 'month') {
    months <- c('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec')
    for (i in seq_along(months)) {
      column_name <- paste0(months[i], '_tavg')
      df_temp_agg[[column_name]] <- mean(df_temp_agg$tavg[df_temp_agg$month == i])
    }
  }
  
  if (resolution == 'season') {
    df_temp_agg <- df %>%
      mutate(winter_tavg = mean(tavg[month %in% (winter)]),
             spring_tavg = mean(tavg[month %in% (spring)]),
             summer_tavg = mean(tavg[month %in% (summer)]),
             fall_tavg = mean(tavg[month %in% (fall)])) 
  }
  
  return(df_temp_agg)
  
  warning("If the season arguments are left blank, this function defaults to winter = c(12, 1, 2, 3), spring = c(4, 5), summer=c(6, 7, 8, 9), fall = c(10, 11)")
}
```

Here is where the categorical variables from the `factor_vars` object (explained above) get converted to factors. This is necessary for the Random Forest procedure to run. 

```{r convert_to_factors}
# Convert categorical variables to factors
df_raw[,factor_vars] <- lapply(df_raw[,factor_vars], factor)

```

This code chunk is where you add your own derived variables that may be important to your analysis. If you wish to aggregate your data in a way different than in our example, this is also the code chunk to do that in.

Below, we do not create any derived variables, aggregate by water year and basinID, then remove unwanted variables.

```{r prepare_data}
# Rename chosen response variable to "response"
df_raw <- df_raw %>% 
  rename("response" = response_var)

no_var = c()
for (col in colnames(df_raw)) {
  if (is.numeric(df_raw[, col])) {
    if (var(df_raw[, col]) == 0) {
      no_var <- append(no_var, col)
    }
  }
}
df_raw <- df_raw %>% select(-all_of(no_var))

# Group by chosen columns
df <- df_raw %>%   
  group_by(across(all_of(group_cols)))

# Aggregate average temperatures using the aggregate_temp() function defined above.
df <- aggregate_temp(df, 'season')

# Create features for peak swe and the peak_swe/precip ratio
df <- df %>% 
  summarise_if(is.numeric, mean) %>% 
  ungroup()

# Reorder response variables first and remove any unwanted variables
df <- df %>% 
  select(response, everything()) %>%
  select(-c(wy, day, month, year, basinID))
```

Here, we split our data into two separate data frames, one for each climate scenario. This will allow us to analyze the impact of  climate on variable importance by calculating different importance ranks for each climate scenario, and comparing how each variable gains or loses importance in a warming climate.

This is an optional split: the `clim` variable could have been left as a column in the original dataframe, in which case climate scenario itself would be used as a predictor variable for NPP. For all scenario-type variables, the user can ultimately choose whether or not it is included as a predictor variable or used as the basis of separation to generate a comparison.


```{r split_data}
if ("clim" %in% names(df)) {

  # Create data frame with only climate scenario 0
  df_clim0 <- df %>% 
    filter(clim == 0) %>% 
    select(-c(clim, wy))
  
  # Create data frame with only climate scenario 2
  df_clim2 <- df %>% 
    filter(clim == 2) %>% 
    select(-c(clim, wy))
  
}  
```

Now, we have two data tables representing the two climate scenarios.

Along with this workflow, this repo also contains a Shiny App. The Shiny App can be used post-analysis to graph some of the relationships that are identified within this feature selection workflow. Here we'll save the newly aggregated datasets to be automatically exported into the Shiny App.

```{r}
save.image(here::here("data", "input", "prepared_data_chap.RData"))
```

